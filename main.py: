import torch
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import logging

class XNAI:
    def __init__(self, model_name="microsoft/DialoGPT-medium"):
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.setup_logging()
        
    def setup_logging(self):
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def load_model(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        try:
            self.logger.info(f"Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {self.model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(self.model_name)
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                
            self.logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False
    
    def preprocess_text(self, text):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„"""
        if not text or not text.strip():
            return ""
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
        cleaned_text = ' '.join(text.strip().split())
        return cleaned_text
    
    def generate_response(self, user_input, max_length=150, temperature=0.7):
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ"""
        if self.model is None:
            return "âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… load_model()"
        
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
            processed_input = self.preprocess_text(user_input)
            
            if not processed_input:
                return "âŒ Ø§Ù„Ù…Ø¯Ø®Ù„ ÙØ§Ø±Øº"
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
            input_ids = self.tokenizer.encode(
                processed_input + self.tokenizer.eos_token, 
                return_tensors='pt'
            )
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
            with torch.no_grad():
                outputs = self.model.generate(
                    input_ids,
                    max_length=input_ids.shape[-1] + max_length,
                    pad_token_id=self.tokenizer.eos_token_id,
                    temperature=temperature,
                    do_sample=True,
                    top_p=0.9,
                    repetition_penalty=1.1
                )
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø¯
            response = self.tokenizer.decode(
                outputs[:, input_ids.shape[-1]:][0], 
                skip_special_tokens=True
            )
            
            return response if response else "ğŸ¤” Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ù†Ø§Ø³Ø¨"
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯: {e}")
            return f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ´ØºÙŠÙ„"""
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ XN.Ai...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    ai = XNAI()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if not ai.load_model():
        print("ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø§Ù„Ø®Ø±ÙˆØ¬...")
        return
    
    print("\nğŸ¤– XN.Ai Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©!")
    print("Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©\n")
    
    # Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    while True:
        try:
            user_input = input("ğŸ‘¤ Ø£Ù†Øª: ").strip()
            
            if user_input.lower() in ['Ø®Ø±ÙˆØ¬', 'exit', 'quit']:
                print("Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©! ğŸ‘‹")
                break
            
            if not user_input:
                continue
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
            response = ai.generate_response(user_input)
            print(f"ğŸ¤– XN.Ai: {response}\n")
            
        except KeyboardInterrupt:
            print("\n\nØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
            break
        except Exception as e:
            print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")

if __name__ == "__main__":
    main()
